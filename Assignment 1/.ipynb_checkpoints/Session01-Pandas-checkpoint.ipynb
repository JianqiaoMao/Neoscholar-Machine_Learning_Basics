{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neoscholar Machine Learning Tutorials\n",
    "### Session 01. Introduction to Numpy, Pandas, Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "1. Numpy\n",
    "2. Pandas\n",
    "3. Matplotlib\n",
    "4. EDA(Exploratory Data Analysis)\n",
    "\n",
    "### Aim\n",
    "At the end of this session, you will be able to:\n",
    "- Understand the basics of numpy.\n",
    "- Understand the basics of pandas.\n",
    "- Understand the basics of matplotlib.\n",
    "- Perform an Exploratory Data Analysis (EDA).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pandas\n",
    "Pandas is another essential open-source library in Python, and today it is widely used by data scientists and ML Engineers. It is built by Wes McKinney based on numpy. The name 'Pandas' is originated from the term \"Panel Data\", an econometrics term for datasets that include observations over multiple time periods for the same object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Basics of Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this shell if you haven't installed pandas library\n",
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main data structures of pandas are **Series** and **DataFrame**, where data are stored and manipulated. A `Series` can simply understood as a column and a `DataFrame` as a table that has many Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series([1, 2, 3, np.nan, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's see how they are different!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Series using pandas.Series()\n",
    "# This is just one of many ways to initialise a pandas series\n",
    "module_score_dic = {'Database': 90, 'Security': 70, 'Math': 100, 'Machine Learning': 80}\n",
    "module_score = pd.Series(module_score_dic)\n",
    "print(\"Module_score: \\n\", module_score, '\\n')\n",
    "print(\"type: \", type(module_score), '\\n')\n",
    "\n",
    "# Creating a DataFrame using pandas DataFrame()\n",
    "dataframe = pd.DataFrame(module_score, columns=['score'])\n",
    "# dataframe = pd.DataFrame(module_score, index=[x for x in module_score.keys()], columns=['score'])\n",
    "print(\"dataframe: \\n\", dataframe, '\\n')\n",
    "print(\"type: \", type(dataframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series can also be a Dataframe that has only one attribute.  \n",
    "**Now let's make a Dataframe that has multiple attributes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_data = {\n",
    "    'Name' : [\"Mercury\", \"Venus\", \"Earth\", \"Mars\", \"Jupiter\", \"Saturn\", \"Uranus\", \"Neptune\"],\n",
    "    'Satellite' : [0, 0, 1, 2, 79, 60, 27, 14],\n",
    "    'AU' : [0.4, 0.7, 1, 1.5, 5.2, 9.5, 19.2, 30.1],\n",
    "    'Diameter (in 1Kkm)' : [4.9, 12.1, 12.7, 6.8, 139.8, 116.5, 50.7, 49.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_system = pd.DataFrame(solar_data, index = [i for i in range(1, 9)])\n",
    "solar_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_system.dtypes # check data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select what to read from the DataFrame by using methods that df.DataFrame has.\n",
    "\n",
    "- `head()` : Returns the first n data\n",
    "- `tail()` : Returns the last n data\n",
    "- `index` : Returns the index\n",
    "- `columns` : Returns the column\n",
    "- `loc` : Returns the information of that row\n",
    "- `values` : Returns only the values without index and column names\n",
    "- `describe()` : Outputs satatistical summary a DataFrame\n",
    "- `sort_values(self, by, axis = 0, ascending = True, inplace = False)` : Sort the DataFrame\n",
    "- `drop()` : Drops selected row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = solar_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # the default value in the bracket is 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: df.loc[0] gives you an error, but df.iloc[0] works fine. You see why? \n",
    "# Try playing around with different numbers and find out why before you google it!\n",
    "# Google search keyword: df.loc vs df.iloc\n",
    "\n",
    "df.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by = 'Diameter', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: re-sort the DataFrame by the number of satellite in descending order.\n",
    "df.sort_values(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before 2006, Pluto was classified as a planet of the solar system. Let's bring him back to our solar system, by adding Pluto to our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[9] = [\"Pluto\", 0, 39.5, 2.38]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reclassify pluto as a dwarf planet again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To drop pluto, you either do df.drop(index=idx) or df.drop(df.index[idx])\n",
    "df.drop(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Read Data with Pandas\n",
    "Pandas supports loading, reading, and writing data from/to various file format, including CSV, JSON and SQL, by converting it to a DataFrame. \n",
    "1. `pd.read_csv()` : Read CSV files\n",
    "2. `pd.read_json()` : Read JSON files\n",
    "3. `pd.read_sql_query()` : Read SQL files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try each option, and see what the difference is.\n",
    "# Option 1\n",
    "movie = pd.read_csv(\"./data/IMDB-Movie-Data.csv\", index_col = \"Title\")\n",
    "\n",
    "#Option 2\n",
    "# movie = pd.read_csv(\"./data/IMDB-Movie-Data.csv\")\n",
    "print(type(movie))\n",
    "movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do: Extract third row\n",
    "movie.iloc[2]\n",
    "# movie.loc[\"Split\"]\n",
    "# movie.loc[2]    --> Is this going to work? if not, why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do: Sort the table by Ratings, in descending order\n",
    "# Do you agree with the rankings? :)\n",
    "movie.None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To Do: Sort the table by 'Revenue(Millions)', in ascending order and print the first 3 rows out\n",
    "movie.None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The value_counts() function is used to get a Series containing counts of unique values\n",
    "movie['Genre'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is called a \"Masking Operation\"\n",
    "# filter out movies that have runtime under 170 minutes and sort the result by rating in descending order.\n",
    "movie[movie['Runtime (Minutes)'] >= 170].sort_values(by=\"Rating\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do: By using masking operation, Extract the movies whose 'Metascore' is bigger than 95, and sort the result from the most recent to the least recent\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do: Extract movies whose directed by one of UCL Alumni ---> Hint: Tenet, Inception\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Pandas Exercise\n",
    "\n",
    "To Do: Extract the movie list that meets requirements below:\n",
    "- 1. Released after 2010 (key = 'Year') (including year 2010)\n",
    "- 2. Runtime is shorter than 150 minutes (key = 'Runtime (Minutes)')\n",
    "- 3. Rating is above 8.0 (key = 'Rating')  \n",
    "\n",
    "Print out only the first 3 movies from the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 How to deal with Missing Data\n",
    "To represent missing data, pandas use np.nan. Data scientists and machine learning engineers sometimes just remove missing data. However, it heavily depends on which data are missing, how big the missing data are and so on. You can fill the missing part with 0, with the mean value of the column or with mean value of only 10 nearest value in the column. It is important for you to choose the way how you are going to deal with missing data.\n",
    "- `isnull()`: returns True or False, depending on the cell's null status. \n",
    "- `sum()`: This can be used as a trick when you count the number of True's. Once the Dataframe is filtered through isnull() function, sum of all True's in a column gives you how many fields have missing data in them.\n",
    "- `dropna()`: deletes any row that contains any single null value.\n",
    "- `fillna(value)`: Fill missing value with the given values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at \"Take Me Home Tonight\" and \"Search Party\"\n",
    "movie.fillna(value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping the rows that contain missing data, the shape of the dataFrame has changed, from (1000, 11) to (838, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Merging Data\n",
    "Some of you who know SQL might have felt that pandas is quite similar to query language.\n",
    "What is the most popular thing that you do in most of the relational database query language?  \n",
    "Yes! (terminologies alert!) Inner JOIN, Outer JOIN, Left JOIN, Right JOIN, Full JOIN...\n",
    "- `concat()` : Concatenation. Used to merge two or more pandas object.\n",
    "- `merge()` : Behaves very simlar to SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll gonna create random dataframe, named df1 and df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.random.randn(10, 2))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(np.random.randn(10, 3))\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis = 1)     # axis setting is very common in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demis = pd.DataFrame(\n",
    "    {'Modules': ['Bioinformatics', 'Robotic Systems', 'Security', 'Compilers'], 'Demis' : [75, 97, 64, 81]}\n",
    ")\n",
    "demis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sedol = pd.DataFrame(\n",
    "    {'Modules': ['Bioinformatics', 'Robotic Systems', 'Security', 'Compilers'], 'Sedol' : [63, 78, 84, 95]})\n",
    "sedol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.merge(demis, sedol, on = 'Modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To Do at home: Define your own dataframe and use functions introducesd above to concatenate or merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your own trial code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to do next?\n",
    "Below websites would be helpful for your further study on pandas library:\n",
    "- [Pandas official website](https://pandas.pydata.org)\n",
    "- [10 minutes to Pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html)\n",
    "- [Data Wrangling with Pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
